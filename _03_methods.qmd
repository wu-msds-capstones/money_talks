## Methods

This section details our comprehensive approach to detecting market manipulation in real-time trading environments. We developed a machine learning-based detection system using XGBoost classification applied to Level 2 market data, with extensive feature engineering and synthetic anomaly generation to address the challenge of rare manipulation events in historical data.

## Data Sources and Collection

Our research combined three complementary data sources to create a comprehensive dataset for manipulation detection:

**Level 2 Market Data (Primary Source):** We collected real-time order book data through the Alpaca Markets API, which provides institutional-grade access to NYSE and NASDAQ Level 2 data feeds. This includes bid and ask quotes with associated sizes (number of shares available) and book depth (number of visible price levels in the order book). Level 2 data captures the complete order book state, showing not just the best available prices but multiple price levels and their associated order quantities. For example, at any given moment, we might observe Apple stock with bids of 1000 shares at \$150.00, 500 shares at \$149.99, and 300 shares at \$149.98, along with corresponding ask levels. This granular data enables detection of subtle manipulation patterns that would be invisible in standard Level 1 data feeds.

**SEC EDGAR Regulatory Filings:** We systematically collected regulatory filings from the Securities and Exchange Commission's EDGAR database, specifically targeting Forms 8-K (current reports), 10-K (annual reports), and Form 4 (insider trading reports) that disclosed enforcement actions or manipulation investigations. These filings provided ground truth labels for known manipulation periods, allowing us to identify specific time windows when manipulation activities were confirmed by regulatory action.

**Synthetic Anomaly Labels:** To address the fundamental challenge of data imbalance in manipulation detection - where normal trading vastly outnumbers manipulation events - we developed a labeling methodology based on statistical anomaly detection. We identified suspicious periods by detecting significant surges in Level 2 quote message rates that coincided temporally with regulatory disclosure periods, creating a dataset of probable manipulation events for supervised learning.

---

## Feature Engineering and Data Processing

Our feature engineering process transformed raw Level 2 market data into analytically meaningful variables designed to capture manipulation patterns. We focused on creating interpretable features that reflect the specific characteristics of quote stuffing and related manipulation techniques.

**Core Market Microstructure Features:**

- **`price`**: Best bid or ask price at time *t*, representing the most competitive available price for buying or selling. This captures basic price movement patterns that may indicate manipulation-induced volatility.

- **`size`**: Number of shares available at the best price level. Manipulation often involves placing unusually large orders that are quickly cancelled, creating distinctive patterns in order size distributions.

- **`total_levels`**: Depth of the order book, measured as the total number of visible price levels containing orders. Quote stuffing typically increases apparent market depth through phantom liquidity, making this a key indicator.

**Advanced Manipulation Indicators:**

- **Order book imbalance**: The ratio of total bid quantity to total ask quantity across all visible levels, calculated as (total_bid_size - total_ask_size) / (total_bid_size + total_ask_size). Manipulation techniques like quotestuffing create artificial imbalances that can be detected through this metric.

- **Order rate per 100ms**: Messages per second rate for each security, capturing the "excessive messaging" characteristic of quote stuffing attacks. Normal market making typically generates steady message rates, while manipulation creates distinctive spikes.

- **Spread**: The spread is the difference between the last ask price and the last bid price in the time window. Quotestuffing typically creates artificial spread patterns.

Our feature selection prioritized interpretability and direct relevance to known manipulation tactics, ensuring that model predictions could be explained to regulatory authorities and market participants. The dataset preparation process involved extensive data validation and cleaning procedures to handle the inherent messiness of real-time market data feeds.

---

## Machine Learning Model Development

We selected XGBoost (eXtreme Gradient Boosting) as our primary classification algorithm for several technical and practical reasons. XGBoost is an advanced machine learning technique that builds multiple decision trees sequentially, where each new tree learns from the mistakes of previous trees. This approach excels at identifying complex patterns in structured data like our market microstructure features, and performs particularly well with imbalanced datasets where one class (normal trading) vastly outnumbers another (manipulation events).

**Model Configuration:**
- **Target Variable**: Binary classification where `1` indicates detected anomaly/manipulation and `0` indicates normal market behavior
- **Training/Testing Split**: 80% of data used for model training, 20% reserved for unbiased performance evaluation, with stratified sampling to maintain class balance proportions in both sets
- **Evaluation Metric**: Log loss (logarithmic loss), which penalizes confident but incorrect predictions more heavily than uncertain predictions, making it ideal for scenarios where false positives and false negatives have different costs

**Addressing Data Imbalance:**
The fundamental challenge in manipulation detection lies in extreme class imbalance - normal trading events outnumber manipulation events by ratios of 100:1 or higher. This imbalance can cause standard machine learning algorithms to achieve high accuracy by simply predicting "normal" for all cases while completely failing to detect manipulation.

We addressed this through several techniques:
- **`scale_pos_weight`**: Set to the ratio of negative to positive samples (normal/anomaly), instructing XGBoost to treat each anomaly sample as equivalent to multiple normal samples during training
- **Threshold optimization**: Rather than using the default 0.5 probability threshold for classification, we systematically explored different thresholds to optimize the precision/recall tradeoff based on business requirements (whether false positives or false negatives are more costly)

**Hybrid Bottlenecked Autoencoder/OC-SVM**

The system implements a two-stage hybrid anomaly detection approach specifically designed for identifying quote stuffing in financial markets. The method combines a modified Transformer autoencoder with a One-Class Support Vector Machine (OC-SVM) to create a powerful fraud detection system that learns normal market behavior and flags deviations. This approach is based on the methodology described by Poutre et al. (2024), who demonstrated that such hybrid frameworks achieve state-of-the-art performance in detecting trade-based manipulations without requiring prior knowledge of manipulation patterns.

An autoencoder is a neural network designed to learn efficient representations of data by training it to reconstruct its input. The network consists of two main components:

1. **Encoder**: Maps input data $X$ to a lower-dimensional representation $Z$
2. **Decoder**: Reconstructs the original input from the representation
Mathematically, this can be expressed as:
$$
\begin{align}
Z &= f_{\text{encoder}}(X) \\
\hat{X} &= f_{\text{decoder}}(Z) \\
\mathcal{L} &= ||X - \hat{X}||^2 \quad \text{(reconstruction error)}
\end{align}
$$

**The Bottleneck Modification**

The "bottlenecked" aspect refers to a critical architectural choice that forces the model to learn compressed, meaningful representations. As described by Poutre et al. (2024), this modification was inspired by sentence embedding techniques but adapted specifically for financial time series anomaly detection. It functions as follows:

1. **Standard Transformer Processing**: Input sequences (25 time windows Ã— 23 features) pass through 6 Transformer encoder layers with multi-head attention
2. **Bottleneck Compression**: The Transformer output is flattened and projected through a linear layer to just 128 dimensions  
3. **Reconstruction**: The 128-dimensional representation is projected back to the original dimensionality

This bottleneck forces the model to learn the most essential patterns in normal market behavior, discarding noise and irrelevant details.

**Stage 2: One-Class SVM on Learned Representations**

One-Class SVM is an unsupervised learning algorithm designed to identify outliers by learning the boundary of normal data. Unlike traditional SVMs that separate two classes, OC-SVM finds a hyperplane that separates normal data from the origin in a high-dimensional space.

## Detection Process

When detecting anomalies in new data, the system follows this pipeline:

```{mermaid}
flowchart TD
    A[Raw Market Data] --> B[Feature Extraction]
    B --> C[Sequence Creation]
    C --> D[Transformer Encoder]
    D --> E[OC-SVM Decision Function]
    E --> F[Classification]
```

The final dissimilarity score combines information from both components:

- **Autoencoder**: How well the data can be reconstructed (implicit in representations)
- **OC-SVM**: How far the representation is from the learned normal boundary

## Observation-Level Scoring

The system implements a sophisticated observation-level scoring mechanism that accounts for the overlapping nature of sequences, following the methodology described by Poutre et al. (2024). Since each market observation can be part of multiple 25-step sequences, the final anomaly score for an observation is calculated as follows:

$\text{dissimilarity}(x_t) = \frac{1}{|S_{x_t}|} \sum_{s \in S_{x_t}} \text{dissimilarity}(s)$

where $S_{x_t}$ is the set of all sequences containing observation $x_t$. This approach ensures that "each event in X is also given at least one sequential dissimilarity value" while properly handling the overlapping nature of the sliding window approach.



---

## Model Evaluation and Validation

Our evaluation framework employed multiple complementary metrics to assess model performance across different aspects of manipulation detection effectiveness.

**Performance Metrics:**
- **Classification Report**: Provides precision (what percentage of predicted anomalies are actually anomalies), recall (what percentage of actual anomalies are correctly identified), and F1-score (harmonic mean of precision and recall) for both normal and anomaly classes. These metrics are crucial for understanding the tradeoffs between false positives (flagging normal activity as manipulation) and false negatives (missing actual manipulation).

- **Confusion Matrix**: A 2x2 table showing the distribution of predictions versus actual labels, enabling clear visualization of model performance across both classes and identification of specific error patterns.

- **Feature Importance Analysis**: XGBoost's built-in feature importance ranking based on information gain, showing which market microstructure features contribute most to manipulation detection. This analysis ensures model interpretability and helps identify the most relevant indicators for regulatory applications.

**Validation Approach:**
We systematically explored probability threshold optimization using XGBoost's `predict_proba` function, which returns prediction confidence scores rather than binary classifications. By adjusting the decision threshold above or below the default 0.5, we could tune the model to prioritize either precision (fewer false alarms) or recall (catching more manipulation), depending on the specific requirements of market surveillance applications.

The final implementation represents a balance between academic rigor and practical applicability, with extensive validation against both synthetic and real-world manipulation patterns [@Chen2016].

